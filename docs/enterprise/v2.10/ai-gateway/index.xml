<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI Gateway - API Gateway for LLMs on KrakenD - Open source API Gateway</title><link>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/</link><description>Recent content in AI Gateway - API Gateway for LLMs on KrakenD - Open source API Gateway</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 21 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/index.xml" rel="self" type="application/rss+xml"/><item><title>AI Security</title><link>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/security/</link><pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><guid>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/security/</guid><description>Protecting sensitive AI data and controlling access is essential for trustworthy AI workloads. KrakenD&amp;rsquo;s AI Gateway integrates multiple layers of security at the edge to enforce zero-trust AI operations. From isolated authorization flows to data masking and exfiltration prevention, you can safeguard data traveling between clients and LLM providers without altering your existing API infrastructure.
The following key features are explained in this document:
Isolated Authentication (JWT + API key separation) API Key Injection (backend-only exposure) Data Masking (request &amp;amp; response layers) Exfiltration Prevention Patterns Isolated Authentication KrakenD separates the authentication flows between consumers and LLM on your AI endpoints.</description></item><item><title>AI Token Cost Control &amp; Quotas</title><link>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/budget-control/</link><pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><guid>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/budget-control/</guid><description>AI workloads can quickly generate unpredictable and excessive costs. KrakenD&amp;rsquo;s AI Gateway provides granular token usage monitoring and enforcement to keep your AI expenses transparent and within budget. Features like token quotas, budget alerts, prompt caching, and intelligent routing enable you to optimize requests and avoid surprise bills while maintaining performance and scalability.
Token Quota and Budget Enforcement KrakenD Enterprise includes a powerful persistent quota system that&amp;rsquo;s perfect for managing token-based usage quotas in LLM applications, designer for controlling cost, enforcing subscription tiers, and preventing overuse.</description></item><item><title>AI Governance</title><link>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/governance/</link><pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><guid>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/governance/</guid><description>KrakenD AI Governance empowers organizations to deploy large language models responsibly by enforcing compliance, security, and operational guardrails inline with AI traffic. Leverage granular controls on prompts, responses, usage, and reuse of prompt templates to standardize AI across teams, tenants, and projects.
Prompt Policy Enforcement Prompt policies enforce constraints on input prompts by pattern matching, contextual validation, or checking request metadata to prevent abusive or sensitive content from being processed downstream.</description></item><item><title>Unified LLM Interface</title><link>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/unified-llm-interface/</link><pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><guid>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/unified-llm-interface/</guid><description>The Unified LLM Interface of KrakenD allows you to interact with one or more LLMs, removing the complexity of dealing with LLMs for the end user. It allows you to set the grounds to communicate with LLMs, authenticate, and treat requests and responses back and forth.
LLM Routing KrakenDâ€™s AI Proxy and LLM routing feature enables you to distribute AI requests across multiple Large Language Model providers or instances. This ensures high availability, optimized performance, cost efficiency, developer abstraction, and compliance.</description></item><item><title>AI Gateways's Prompt Templates</title><link>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/prompt-templates/</link><pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><guid>https://www.krakend.io/docs/enterprise/v2.10/ai-gateway/prompt-templates/</guid><description>Prompt Templates are a mechanism to build the body sent to the LLM using a predefined template, instead of allowing the end user passing it directly. This is not only writing a text that you send to the LLM, but actually have the opportunity to insert place holders, values that came in the request body, headers, parameters, etc. or even apply scripting over it.
The Prompt Templates offer more control on the types of requests sent to the AI and allow you to specify system and user input to ensure the final output.</description></item></channel></rss>